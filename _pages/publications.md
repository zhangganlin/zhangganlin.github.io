
<!-- <hr>

  You can also find my articles on my <a href="https://scholar.google.com/citations?user=1B_T56IAAAAJ" target="_blank">Google Scholar profile</a>.

<hr> -->
  <heading><strong>GlORIE-SLAM: Globally Optimized RGB-only Implicit Encoding Point Cloud SLAM</strong> </heading>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
    <tr onmouseout="glorie_stop()" onmouseover="glorie_start()">  
            <td width="40%">
              <div class="one">
                <div class="two" id='glorie_shape'>
                  <video  autoplay muted loop playsinline width="100%">
                    <source src="/images/publications/glorie.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <img src='/images/publications/glorie.jpg' style="width: 100%;"/>
              </div>        
              <script type="text/javascript">
              function glorie_start() { 
              document.getElementById('glorie_shape').style.opacity = "1";
              }
              function glorie_stop() { 
              document.getElementById('glorie_shape').style.opacity = "0"; 
              }
              glorie_stop()
              </script>
            </td>
      <td valign="top" width="75%">
            <papertitle>
            <strong>
            <a href="https://zhangganlin.github.io/GlORIE-SLAM/index.html" target="_blank">GlORIE-SLAM: Globally Optimized RGB-only Implicit Encoding Point Cloud SLAM</a>
            </strong>
            </papertitle>
      <br>
          <strong>Ganlin Zhang*</strong>, 
          <a href="https://eriksandstroem.github.io/" target="_blank">Erik Sandstr√∂m*</a>, 
          <a href="https://youmi-zym.github.io/" target="_blank"> Youmin Zhang</a>, 
          <a href="https://manthan99.github.io/" target="_blank"> Manthan Patel</a>, 
          <a href="https://vision.ee.ethz.ch/people-details.OTAyMzM=.TGlzdC8zMjcxLC0xOTcxNDY1MTc4.html" target="_blank"> Luc Van Gool</a>, 
          <a href="https://cvg.ethz.ch/team/Dr-Martin-R-Oswald" target="_blank"> Martin R. Oswald</a>
        <br>
          <em>Preprint on ArXiv, 2024</em>
        <br>
        <a href="https://github.com/zhangganlin/GlORIE-SLAM" target="_blank">Github Repo </a> | 
        <a href="https://arxiv.org/abs/2403.19549" target="_blank">ArXiv</a> | 
        <a href="https://zhangganlin.github.io/GlORIE-SLAM/index.html" target="_blank">Project website</a>
        <br>
        1. A monocular SLAM pipeline with deformalbe neural pointcloud scene representation. <br>
        2. Novel DSPO layer for BA, which can jointly optimize depth map, depth scale and camera pose. <br>
         </td>
    </tr>
  </table>
  <hr>



<heading><strong>Revisiting Rotation Averaging: Uncertainties and Robust Losses</strong> </heading>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">  
    <td width="40%">
      <div class="one">
      <img src="/images/publications/rotationAverage.png" width="100%"> </div>
    </td>
    <td valign="top" width="75%">
          <papertitle>
          <strong>
            <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zhang_Revisiting_Rotation_Averaging_Uncertainties_and_Robust_Losses_CVPR_2023_paper.pdf" target="_blank">Revisiting Rotation Averaging: Uncertainties and Robust Losses</a>
          </strong>
          </papertitle>
    <br>
        <strong>Ganlin Zhang</strong>,
        <a href="https://vlarsson.github.io/" target="_blank">Viktor Larsson</a>,
        <a href="https://people.inf.ethz.ch/dbarath/" target="_blank">Daniel Barath</a>
      <br>
        <em>Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</em>
      <br>
      <a href="https://github.com/zhangganlin/GlobalSfMpy" target="_blank">Github Repo</a> | 
      <a href="https://arxiv.org/abs/2303.05195" target="_blank">ArXiv</a>
      <br>
      1. Better model the underlying noise distributions by directly propagating the uncertainty from the point correspondences into the rotation averaging. <br>
      2. Integrate a variant of the MAGSAC++ loss into the rotation averaging, instead of using the classical robust losses.
    </td>
</table>
<hr>

